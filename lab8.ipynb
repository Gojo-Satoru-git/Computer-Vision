{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f33188-271d-4478-b698-5d64d65b63e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "\n",
    "def download_images(query, max_images, save_dir):\n",
    "    # Set up Selenium WebDriver\n",
    "    driver = webdriver.Chrome()  # Use the path to your ChromeDriver if necessary\n",
    "    driver.get(f\"https://www.google.com/search?tbm=isch&q={query}\")\n",
    "\n",
    "    # Create the directory to save images\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Scroll and collect image URLs\n",
    "    image_urls = set()\n",
    "    while len(image_urls) < max_images:\n",
    "        thumbnails = driver.find_elements(By.CSS_SELECTOR, \"img.rg_i\")\n",
    "        for img in thumbnails[len(image_urls):]:\n",
    "            try:\n",
    "                img.click()\n",
    "                time.sleep(2)\n",
    "                larger_image = driver.find_element(By.CSS_SELECTOR, \"img.n3VNCb\")\n",
    "                src = larger_image.get_attribute(\"src\")\n",
    "                if src.startswith(\"http\") and len(image_urls) < max_images:\n",
    "                    image_urls.add(src)\n",
    "            except Exception as e:\n",
    "                print(f\"Error clicking image: {e}\")\n",
    "\n",
    "        # Scroll down to load more images\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "\n",
    "    # Download images\n",
    "    for i, url in enumerate(image_urls):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            with open(os.path.join(save_dir, f\"{query}_{i + 1}.jpg\"), \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"Downloaded: {query}_{i + 1}.jpg\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not download {url}: {e}\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "# Example usage\n",
    "download_images(\"puppies\", max_images=10, save_dir=\"images\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb8ba67-3774-4289-8c34-e3a30b706e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "MIN_MATCH_COUNT = 30\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "flann_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "flann = cv2.FlannBasedMatcher(flann_params, {})\n",
    "\n",
    "dataset_path = \"path/to/positive_samples\"  \n",
    "\n",
    "train_images = []\n",
    "kp_list = []\n",
    "desc_list = []\n",
    "\n",
    "for filename in os.listdir(dataset_path):\n",
    "    img_path = os.path.join(dataset_path, filename)\n",
    "    train_img = cv2.imread(img_path, 0)\n",
    "    if train_img is not None:\n",
    "        kp, desc = sift.detectAndCompute(train_img, None)\n",
    "        if desc is not None:\n",
    "            train_images.append(train_img)\n",
    "            kp_list.append(kp)\n",
    "            desc_list.append(desc)\n",
    "\n",
    "print(f\"Loaded {len(train_images)} training images.\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    kp2, desc2 = sift.detectAndCompute(gray, None)\n",
    "    if desc2 is None:\n",
    "        continue\n",
    "\n",
    "    best_match_count = 0\n",
    "    best_match_outline = None\n",
    "\n",
    "    for i in range(len(train_images)):\n",
    "        matches = flann.knnMatch(desc2, desc_list[i], k=2)\n",
    "        good_matches = [m for m, n in matches if m.distance < 0.75 * n.distance]\n",
    "        \n",
    "        if len(good_matches) > best_match_count:\n",
    "            best_match_count = len(good_matches)\n",
    "            tp = np.float32([kp_list[i][m.trainIdx].pt for m in good_matches])\n",
    "            qp = np.float32([kp2[m.queryIdx].pt for m in good_matches])\n",
    "            H, status = cv2.findHomography(tp, qp, cv2.RANSAC, 3.0)\n",
    "            \n",
    "            if H is not None:\n",
    "                h, w = train_images[i].shape\n",
    "                train_outline = np.float32([[[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]])\n",
    "                best_match_outline = cv2.perspectiveTransform(train_outline, H)\n",
    "    if best_match_count > MIN_MATCH_COUNT and best_match_outline is not None:\n",
    "        cv2.polylines(frame, [np.int32(best_match_outline)], True, (0, 255, 0), 3)\n",
    "        cv2.putText(frame, 'Object Detected', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        print(f\"Match Found: {best_match_count} keypoints\")\n",
    "    else:\n",
    "        print(\"No strong match found\")\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow('Object Detection', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == 27: \n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
